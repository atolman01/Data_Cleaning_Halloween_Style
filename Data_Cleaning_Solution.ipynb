{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Cleaning_Solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atolman01/Data_Cleaning_Halloween_Style/blob/main/Data_Cleaning_Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhiS0wTzy0m9"
      },
      "source": [
        "### **Reading in data and then saving it into a Dataframe:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fetve5uRYfaA",
        "outputId": "80c94dfa-d1aa-4d16-8827-b65aeb488cca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8mpRJQ1ZF7T"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#instead of using default encoding=\"utf-8\", need to use encoding=\"ISO-8859-1\"\n",
        "#use python engine instead of c engine\n",
        "with open(\"/content/drive/My Drive/Datasets/candyhierarchy2017.csv\",'r', encoding=\"ISO-8859-1\") as reader:\n",
        "  df = pd.read_csv(reader, header=0, engine='python')\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snblr5Os5t4N"
      },
      "source": [
        "Reference to encoding hint : https://stackoverflow.com/questions/19699367/for-line-in-results-in-unicodedecodeerror-utf-8-codec-cant-decode-byte"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjPNMEHaHiBK"
      },
      "source": [
        "### **Print the first 10 rows of the dataframe:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RFjGfNxHtkX"
      },
      "source": [
        "#print the first 10 rows of my dataframe\n",
        "df.head(10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ArmboLCHz6Q"
      },
      "source": [
        "What are some of the problems with the data?\n",
        "\n",
        "<ul>\n",
        "  <li> 1. <textarea name=\"first\" rows=1 cols=50></textarea></li>\n",
        "  <li> 2. <textarea name=\"first\" rows=1 cols=50></textarea></li>\n",
        "  <li> 3. <textarea name=\"first\" rows=1 cols=50></textarea></li>\n",
        "</ul>\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5Z8Xzo3zgFD"
      },
      "source": [
        "What are three main causes of dirty data?\n",
        "\n",
        "<ul>\n",
        "  <li> 1. <textarea name=\"first\" rows=1 cols=50></textarea></li>\n",
        "  <li> 2. <textarea name=\"first\" rows=1 cols=50></textarea></li>\n",
        "  <li> 3. <textarea name=\"first\" rows=1 cols=50></textarea></li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mpg-TtA-JGyx"
      },
      "source": [
        "Why is dirty data problematic?\n",
        "\n",
        "<textarea name=\"textbox\" rows=6 cols=100></textarea>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhnJCqKkkZKm"
      },
      "source": [
        "---\n",
        "# **PROBLEM 1: Column Makeover**\n",
        "### **Approach 1 to Consistent Columns**\n",
        "\n",
        "Here we will use control and data structures with Python to clean our columns up. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P53LA-ccrWxi"
      },
      "source": [
        "**In pandas, axis=0 are rows and axis=1 are columns**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvjugCjr4L0Y"
      },
      "source": [
        "# list of candies\n",
        "candies = [\"100 Grand bar\"\n",
        ",'3 Musketeers'\n",
        ",'One dime'\n",
        ",'One quarter'\n",
        ",'Air Heads'\n",
        ",'Almond Joy'\t\n",
        ",'Baby Ruth'\n",
        ",'Black jacks'\t\n",
        ",'Black Licorice'\n",
        ",'Bonkers'\n",
        ",'Boston Baked Beans'\n",
        ",'Bottle Caps'\n",
        ",'Cadbury Creme Eggs'\n",
        ",'Candy Corn'\t\n",
        ",'Caramel Apple Pops'\t\n",
        ",'Caramellos'\n",
        ",'Charleston Chew'\t\n",
        ",'Chewey Lemonhead Fruit Mix'\t\n",
        ",'Chiclets'\t\n",
        ",'Chick-o-Sticks'\n",
        ",'Coffee Crisp'\n",
        ",'Dots'\n",
        ",'Dum Dums'\n",
        ",'Fruit Chews'\t\n",
        ",'Fun Dip'\t\n",
        ",'Gobstopper'\t\n",
        ",'Goo Goo Clusters'\n",
        ",'Haribo Gold Bears'\t\n",
        ",'Haribo Happy Cola'\n",
        ",'Haribo Sour Bears'\n",
        ",'Haribo Twin Snakes'\t\n",
        ",'Heath'\n",
        ",'Hershey\\'s Kisses'\t\n",
        ",'Hershey\\'s Krackel'\t\n",
        ",'Hershey\\'s Milk Chocolate'\n",
        ",'Hershey\\'s Dark Chocolate'\t\n",
        ",'Hershey\\'s Special Dark'\n",
        ",'Jawbusters'\n",
        ",'Jolly Ranchers'\n",
        ",'Junior Mints'\n",
        ",'Kinder Happy Hippo'\n",
        ",'Kit Kat'\t\n",
        ",'Laffy Taffy'\n",
        ",'Lemonhead'\t\n",
        ",'Lifesavers big ring gummies'\t\n",
        ",'Lindt truffle'\n",
        ",'Lollipops'\n",
        ",'Mars'\n",
        ",'Mary Janes'\n",
        ",'Maynards'\n",
        ",'Peanut butter M&M\\'s'\n",
        ",'M&M\\'s'\t\n",
        ",'Mike & Ike'\t\n",
        ",'Milk Duds'\n",
        ",'Milky Way'\n",
        ",'Milky Way Midnight'\t\n",
        ",'Milky Way Simply Caramel'\t\n",
        ",'Mounds'\n",
        ",'Mr Good Bar'\n",
        ",'Nerds'\t\n",
        ",'Butterfinger'\t\n",
        ",'Crunch'\t\n",
        ",'Nik L Nip'\t\n",
        ",'Now & Later'\n",
        ",'Payday'\t\n",
        ",'Peanut M&Ms'\n",
        ",'Peeps'\t\n",
        ",'Pixie Sticks'\t\n",
        ",'Pop Rocks'\t\n",
        ",'Red vines'\n",
        ",'Red Licorice'\t\n",
        ",'Reese\\'s Miniatures'\n",
        ",'Reese\\'s Peanut Butter cup'\n",
        ",'Reese\\'s pieces'\n",
        ",'Reese\\'s stuffed with pieces'\n",
        ",'Reggie Jackson Bar'\n",
        ",'Ring pop'\n",
        ",'Rolos'\t\n",
        ",'Root Beer Barrels'\n",
        ",'Runts'\n",
        ",'Sixlets'\n",
        ",'Skittles'\n",
        ",'Skittles wildberry'\n",
        ",'Nestle Smarties'\n",
        ",'Necco Wafers'\n",
        ",'European Smarties'\n",
        ",'Snickers'\n",
        ",'Snickers Crisper'\n",
        ",'Sour Patch Kids'\n",
        ",'Sour Patch Tricksters'\n",
        ",'Starburst'\n",
        ",'Strawberry bon bons'\n",
        ",'Sugar Babies'\n",
        ",'Sugar Daddy'\n",
        ",'Super Bubble'\n",
        ",'Swedish Fish'\n",
        ",'Sweet tarts'\n",
        ",'Take 5'\n",
        ",'Tic tacs'\n",
        ",'Tootsie Pop'\n",
        ",'Tolberone'\n",
        ",'Tootsie Roll Juniors'\n",
        ",'Tootsie Roll Midgies'\n",
        ",'Tootsie Roll Snack Bars'\n",
        ",'Trolli Sour Bites'\n",
        ",'Trail mix'\n",
        ",'Twix'\n",
        ",'Twizzlers'\n",
        ",'Warheads'\n",
        ",'Welch\\'s Fruit Snacks'\n",
        ",'Werther\\'s Original Caramel'\n",
        ",'Whoppers'\n",
        ",'York Peppermint Patties']\n",
        "\n",
        "# a dictionary ( key - is the current column name we want to change : value - the new column name)\n",
        "cols_rename = {\"anonymous brown globs that come in black and orange wrappers\t(a.k.a. mary janes)\":\"mary janes\"\n",
        "            ,\"bonkers (the candy)\":\"bonkers\"\n",
        "            ,\"state, province, county, etc\":\"state\"\n",
        "            ,\"chick-o-sticks (we donõt know what that is)\":\"chick-o-sticks\"\n",
        "            ,\"gummy bears straight up\":\"gummy bears\"\n",
        "            ,\"jolly ranchers (good flavor)\":\"jolly ranchers\"\n",
        "            ,\"joyjoy (mit iodine!)\":\"almond joy\"\n",
        "            ,\"now'n'laters\":\"now & later\"\n",
        "            ,\"sourpatch kids (i.e. abominations of nature)\":\"sour patch kids\"\n",
        "            ,\"tolberone something or other\":\"tolberone\"\n",
        "            ,\"smarties (commonwealth)\":\"european smarties\"\n",
        "            ,\"smarties (american)\":\"american smarties\"\n",
        "            ,\"licorice (not black)\":\"red licorice\"\n",
        "            ,\"licorice (yes black)\":\"black licorice\"\n",
        "            ,\"going out?\":\"going out\"\n",
        "            ,\"good n' plenty\" : \"good & plenty\"\n",
        "            ,\"laffytaffy\" : \"laffy taffy\"\n",
        "            ,\"mike and ike\" : \"mike & ike\"\n",
        "            ,\"mr. goodbar\" : \"mr good bar\"\n",
        "            ,\"three musketeers\" : \"3 musketeers\"\n",
        "            ,\"mint kisses\" : \"hershey\\'s mint kisses\"\n",
        "            ,\"pixy stix\" : \"pixie sticks\"\n",
        "            ,\"nestle crunch\" : \"crunch\"\n",
        "            ,\"heath bar\" : \"heath\"\n",
        "            ,\"hersheyõs milk chocolate\":\"hershey's milk chocolate\"\n",
        "            ,\"lemonheads\":\"lemonhead\"\n",
        "            ,\"reeseõs peanut butter cups\":\"reese's peanut butter cup\"\n",
        "            ,\"peanut m&mõs\":\"peanut butter m&m's\"\n",
        "            ,\"regular m&ms\":\"m&m's\"}\n",
        "\n",
        "#instead of dealing with a mix of upper and lower case, just make them all lower case\n",
        "candies = [name.lower() for name in candies]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6R7bajsxF5j"
      },
      "source": [
        "# deletes the columns we do not want \n",
        "# IMPORTANT : be careful, only execute this once\n",
        "# After deleting the columns, if you execute this again the columns\n",
        "#   will already be gone and it will return COLUMN NOT FOUND\n",
        "def delete_columns(df,cols_to_drop):\n",
        "  \n",
        "  df = df.drop(cols_to_drop,axis=1)\n",
        "  return df\n",
        "\n",
        "# get the columns we know we want to delete to make it easier with slicing columns later on!\n",
        "# Plus these columns have nothing to do with Trick or Treating!\n",
        "drop = df.loc[:,'Q7: JOY OTHER':'Click Coordinates (x, y)'].append(df[['Internal ID']])\n",
        "drop_cols = [x for x in drop.columns]\n",
        "\n",
        "#uncomment this line when rexecuting for the first time\n",
        "# remember we only want to delete these columns once\n",
        "df = delete_columns(df,drop_cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0wqpt3aUbDq"
      },
      "source": [
        "\n",
        "#strip columns in our original dataframe of whitespace and lower case columns\n",
        "df.columns = [c[4:].strip().lower() for c in df.columns]\n",
        "\n",
        "#find all columns in dataframe that did not have a match in the candies list\n",
        "no_matches = [c for c in df.columns if c not in candies]\n",
        "\n",
        "# returns a tuple with two lists : one with irrelevant columns we do not need, the other with columns we renamed \n",
        "def get_unwanted_cols(no_matches,cols_rename):\n",
        " renamed = []\n",
        " irrelevant_cols = []\n",
        "\n",
        " for current_name in no_matches:\n",
        "   if current_name in cols_rename:\n",
        "     renamed.append(cols_rename[current_name])\n",
        "   elif current_name in [\"country\",\"gender\",\"age\"]:\n",
        "     renamed.append(current_name)\n",
        "   else:\n",
        "     irrelevant_cols.append(current_name)\n",
        "\n",
        " return irrelevant_cols\n",
        "\n",
        "\n",
        "#call all your functions to clean your dataframe columns\n",
        "irrelevant_columns = get_unwanted_cols(no_matches,cols_rename)\n",
        "df = delete_columns(df, irrelevant_columns)\n",
        "df.rename(columns=cols_rename,inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmdUAITi2hzc"
      },
      "source": [
        "###**Approach 2 to Consistent Columns**\n",
        "\n",
        "This approach is more of a hard-coded solution than the one above. \n",
        "\n",
        "You can physically write out every single column you want to delete. But datasets will often have tons and tons of columns that take too much time to hard-code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JuSFi-u4_lm"
      },
      "source": [
        "\n",
        "# a function to rename columns in our dataframe\n",
        "# returns a new dataframe\n",
        "def rename_df_columns(df):\n",
        "  \n",
        "  df.rename(columns={\"anonymous brown globs that come in black and orange wrappers\t(a.k.a. mary janes)\":\"mary janes\"\n",
        "            ,\"bonkers (the candy)\":\"bonkers\"\n",
        "            ,\"state, province, county, etc\":\"state\"\n",
        "            ,\"chick-o-sticks (we donõt know what that is)\":\"chick-o-sticks\"\n",
        "            ,\"gummy bears straight up\":\"gummy bears\"\n",
        "            ,\"jolly ranchers (good flavor)\":\"jolly ranchers\"\n",
        "            ,\"joyjoy (mit iodine!)\":\"almond joy\"\n",
        "            ,\"now'n'laters\":\"now & later\"\n",
        "            ,\"sourpatch kids (i.e. abominations of nature)\":\"sour patch kids\"\n",
        "            ,\"tolberone something or other\":\"tolberone\"\n",
        "            #,\"sweetums (a friend to diabetes)\":\"sweetums\"\n",
        "            ,\"smarties (commonwealth)\":\"european smarties\"\n",
        "            ,\"smarties (american)\":\"nestle smarties\"\n",
        "            ,\"licorice (not black)\":\"red licorice\"\n",
        "            ,\"licorice (yes black)\":\"black licorice\"\n",
        "            ,\"going out?\":\"going out\"\n",
        "            ,\"good n' plenty\" : \"good & plenty\"\n",
        "            ,\"laffytaffy\" : \"laffy taffy\"\n",
        "            ,\"mike and ike\" : \"mike & ike\"\n",
        "            ,\"mr. goodbar\" : \"mr good bar\"\n",
        "            ,\"three muskateers\" : \"3 muskateers\"\n",
        "            ,\"mint kisses\" : \"hershey\\'s mint kisses\"\n",
        "            ,\"pixy sticks\" : \"pixie sticks\"\n",
        "            ,\"nestle crunch\" : \"crunch\"\n",
        "            ,\"heath bar\" : \"heath\"}, inplace=True)\n",
        "  return df\n",
        "\n",
        "#deletes all unwanted columns from our dataframe\n",
        "#returns a new dataframe\n",
        "def delete_df_columns(df):\n",
        "  df = df.drop(['Internal ID','Q6 | Any full-sized candy bar','Q6 | Bonkers (the board game)','Q6 | Box\\'o\\'Raisins'\n",
        "    , 'Q6 | Broken glow stick', 'Q6 | Candy that is clearly just the stuff given out for free at restaurants'\n",
        "    , 'Q6 | Cash, or other forms of legal tender', 'Q6 | Chardonnay', 'Q6 | Creepy Religious comics/Chick Tracts'\n",
        "    , 'Q6 | Dental paraphenalia', 'Q6 | Dove Bars', 'Q6 | Fuzzy Peaches','Q6 | Generic Brand Acetaminophen'\n",
        "    , 'Q6 | Glow sticks', 'Q6 | Gum from baseball cards', 'Q6 | Healthy Fruit','Q6 | Hugs (actual physical hugs)'\n",
        "    , 'Q6 | Jolly Rancher (bad flavor)','Q6 | Kale smoothie', 'Q6 | Senior Mints', 'Q6 | Blue M&M\\'s', 'Q6 | Red M&M\\'s', 'Q6 | Green Party M&M\\'s'\n",
        "    , 'Q6 | Independent M&M\\'s', 'Q6 | Abstained from M&M\\'ing.' , 'Q6 | Mint Juleps', 'Q6 | Pencils', 'Q6 | Real Housewives of Orange County Season 9 Blue-Ray'\n",
        "    , 'Q6 | Sandwich-sized bags filled with BooBerry Crunch', 'Q6 | Spotted Dick', 'Q6 | Those odd marshmallow circus peanut things'\n",
        "    , 'Q6 | Vials of pure high fructose corn syrup, for main-lining into your vein', 'Q6 | Vicodin', 'Q6 | Whatchamacallit Bars'\n",
        "    , 'Q6 | White Bread', 'Q6 | Minibags of chips','Q6 | Hard Candy','Q6 | Whole Wheat anything', 'Q7: JOY OTHER', 'Q8: DESPAIR OTHER', 'Q9: OTHER COMMENTS', 'Q10: DRESS'\n",
        "    , 'Unnamed: 113', 'Q11: DAY', 'Q12: MEDIA [Daily Dish]', 'Q12: MEDIA [Science]','Q12: MEDIA [ESPN]','Q12: MEDIA [Yahoo]', 'Click Coordinates (x, y)'],axis=1)\n",
        "\n",
        "  return df\n",
        "\n",
        "#call functions above and return \n",
        "# new dataframe with changes\n",
        "def clean_df_columns(df):\n",
        "  temp_list = []\n",
        "  removed_col = delete_df_columns(df)\n",
        "  \n",
        "  for c in removed_col.columns:                # go through all columns that are left in dataframe\n",
        "    temp_list.append(c[4:].strip().lower())    #slice the name, and strip it of all whitespace and lower case \n",
        "  removed_col.columns = temp_list\n",
        "  renamed_df = rename_df_columns(removed_col) #rename columns\n",
        "  return renamed_df\n",
        "\n",
        "\n",
        "clean_df_col = clean_df_columns(df)\n",
        "print(clean_df_col.columns)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf6wcvHc3nQr"
      },
      "source": [
        "---\n",
        "# **Problem 2:** Null Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBVjq6pezKpn"
      },
      "source": [
        "#drop rows with all NaN values \n",
        "\n",
        "no_nulls = clean_df_col.dropna(axis=0,how='all')\n",
        "\n",
        "#print(no_nulls)\n",
        "\n",
        "filtered = no_nulls[no_nulls['going out'] == 'Yes']\n",
        "filtered.reset_index()\n",
        "print(filtered)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}